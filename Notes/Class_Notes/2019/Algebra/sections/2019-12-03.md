
# Tuesday December 3rd

## Similarity and Diagonalizability

Recall that $A \sim B \iff A = PBP\inv$.

*Fact:*
If $T:V \to V$ is a linear transformation and $\mathcal{B}, \mathcal{B}'$ are bases where $[T]_{\mathcal{B}} = A$ and $[T]_{\mathcal{B}'}$, then $A \sim B$.

**Theorem:**
Let $A$ be an $n\times n$ matrix.
Then

1. $A$ is similar to a diagonal matrix / diagonalizable $\iff A$ has $n$ linearly independent eigenvectors.

2. $A = PDP\inv$ where $D$ is diagonal and $P = [\vector{v_1}, \vector{v_2}, \cdots, \vector{v_n}]$ with the $\vector{v_i}$ linearly independent.

*Proof:*
Consider $AP = PD$, then $AP$ has columns $A\vector{v_i}$ and $PD$ has columns $\lambda_i \vector{v_i}$.
$\qed$

*Corollary:*
If $A$ has distinct eigenvalues, then $A$ is diagonalizable.

*Examples:*

1. Let
$$
A =
\left[\begin{array}{ccc}
4 & 0 & 0 \\
-1 & 4 & 0 \\
0 & 0 & 5
\end{array}\right]
$$

    $A$ has eigenvalues $4,5$, and it turns out that $A$ is defective.

    Note that $\dim \Lambda_4 + \dim \Lambda_5 = 2 < 3$, so the eigenvectors can't form a basis of $\RR^3$.

2.
$$
A =
\left[\begin{array}{ccc}
4 & 2 & 2 \\
2 & 4 & 2 \\
2 & 2 & 4
\end{array}\right]
$$
  $A$ has eigenvalues $2, 8$.
  $\Lambda_2 = \spanof_\RR\theset{[-1, 1, 0]^t, [-1, 0, 1]^t}$ and $\Lambda_8 = \spanof_\RR\theset{[1,1,1]^t}$.
  These vectors become the columns of $P$, which is (by no coincidence!) an orthogonal matrix, since $A$ was symmetric.

*Exercise*:
\begin{align*}
\left[\begin{array}{ccc}
0 & 4 & 2 \\
-1 & -4 & -1 \\
0 & 0 & -2
\end{array}\right]
.\end{align*}

Find $J = JCF(A)$ (so $A = PJP\inv$) and compute $P$.

**Definition:**
Let $A = (a_{ij})$, then define that *trace* of $A$ by $\tr(A) = \sum_i a_{ii}$.

The trace satisfies several properties:

- $\tr(A+B) = \tr(A) + \tr(B)$,

- $\tr(kA) = k\tr(A)$,

- $\tr(AB) = \tr(BA)$.

**Theorem:**
Let $T: V\to V$ be a linear transformation with $\dim V < \infty$, $A = [T]_{\mathcal{B}}$ with respect to some basis, and $p_T(x)$ be the characteristic polynomial of $A$.

Then
\begin{align*}
p_T(x) &= x^n + c_{n-1}x^{n-1} + \cdots + c_1 x + c_0, \\
c_0 &= (-1)^n \det(A), \\
c_{n-1} &= -\tr(A)
.\end{align*}

*Proof:*
We have $p_T(0)  = \det(0 I_n - A) = \det(-A) = (-1)^n \det(A)$.

Compute $p_T(x)$ by expanding $\det{xI - A}$ along the first row.
The first term looks like $\prod (x-a_{ii})$, and no other term contributes to the coefficient of $x^{n-1}$.

$\qed$

**Definition:**
A *Lie Algebra* is a vector space with an operation $[\wait, \wait]: V\cross V \to V$ satisfying

1. Bilinearity,

2. $[x, x] = 0$,

3. The Jacobi identity $[x, [y, z]] = [y, [z, x]] + [z, [x, y]] = 0$.

*Examples:*

1. $L = \liegl(n, \CC) = n \times n$ invertible matrices over $\CC$ with $[A, B] = AB - BA$.

2. $L = \liesl(n, \CC) = \theset{A \in \liegl(n, \CC) \mid \tr(A) = 0}$ with the same operation, and it can be checked that
$$
\tr([A, B]) = \tr(AB - BA) = \tr(AB) - \tr(BA) = 0
.$$

  > This turns out to be a *simple* algebra, and simple algebras over $\CC$ can be classified using root systems and Dynkin diagrams -- this is given by type $A_{n-1}$.
