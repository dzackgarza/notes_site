# Tuesday November 26th

## Differentiation

*Question:*
Let $f\in L^1([a, b])$ and $F(x) = \int_a^x f(y) ~dy$.
Is $F$ differentiable a.e. and $F' = f$?

If $f$ is continuous, then absolutely yes.

Otherwise, we are considering 
$$
\frac{f(x+h) - F(x)}{h} = \frac{1}{h} \int_x^{x+h} f(y)~dy \to_? f(x)
$$

so the more general question is
$$
\lim_{\substack{m(I) \to 0 \\  x\in I}} \frac{1}{m(I)} \int_I f(y) ~dy =_? f(x) ~\text{a.e.}
$$

Note that if $f$ is continuous, since $[a, b]$ is compact, we have uniform continuity and 
$$
\frac{1}{m(I)} \int_I f(y) - f(x) ~dy < \frac{1}{m(I)} \int_I \varepsilon \to 0
.$$

## Lebesgue Differentiation and Density Theorems

**Theorem:**
If $f\in L^1(\RR^n)$ then
$$
\lim_{\substack{m(B) \to 0 \\ x\in B}} \int \frac{1}{m(B)} \int_B f(y)~dy = f(x) ~\text{a.e.}
$$

> Note: although it's not obvious at first glance, this really is a theorem about differentiation.

**Corollary (Lebesgue Density Theorem):**
For any measurable set $E \subseteq \RR^n$, we have
$$
\lim_{r\to 0} \frac{m(E\intersect B_r(x))}{m(B_r(x))} = 1 ~a.e.
$$

*Proof:*
Let $f = \chi_E$ in the theorem.

We want to show 
$$
Df(x) \definedas \limsup_{\substack{m(B) \to 0 \\ x\in B}} \abs{\frac{1}{m(B)} \int_B (f(y) - f(x))~dy  } \to 0
$$

Note that we can replace $\limsup \cdots$ with 
$$
\lim_{\varepsilon \to 0} \sup_{\substack{0\leq m(B) \leq \varepsilon \\ x\in B}} \cdots
,$$


which is well defined as it is a decreasing sequence of numbers bounded below by zero.

Next we'll introduce that *Hardy-Littlewood Maximal Function*, given by 
$$
Mf(x) \definedas \sup_{x\in B} \frac{1}{m(B)} \int_B \abs{f(y)} ~dy
$$

> *Exercise*: show that $Mf$ is a measurable function. 
(Hint: it's easy to show that the appropriate preimage is open.)

**Theorem (Hardy-Littlewood Maximal Function Theorem):**
Let $f\in L^1(\RR^n)$, then 
$$
m({ x\in \RR^n \suchthat Mf(x) > \alpha  }) \leq \frac{3^n}{\alpha} \norm{f}_1.
$$

> Idea: if you look at all balls intersecting a given ball of radius $\alpha$, the worst case is that the other ball doesn't intersect and is of the same radius. But then you can draw a ball of radius $3\alpha$ and cover every such intersecting ball.

> Exercise: As a corollary, $Mf(x) < \infty~a.e.$

This is called a *weak type* estimate, compared to a strong type $\norm{Mf}_1 \leq C \norm{f}_1$. 
Note that by Chebyshev, a strong estimate would imply the weak one because
$$
m(\theset{x \suchthat mf(x) > \alpha}) \leq \frac{1}{\alpha} \norm{Mf}_1 \not\leq \frac{C}{\alpha} \norm{f}_1,
$$

which is an inequality that doesn't hold (hence the theorem) because there is an $L^1$ function for which $Mf$ is *not* $L^1$.

*Proof of differentiation theorem:*
The goal is to show $Df(x) = 0$ a.e.

We will show that $m(\theset{x\suchthat Df(x) > \alpha}) = 0$ for all $\alpha > 0$.

**Some facts:**

1. If $g$ is continuous, then $Dg(x) = 0$ a.e. by uniform convergence.

2. 
$$
D(f_1 + f_2)(x) \leq Df_1(x) + Df_2(x)
$$ 
by applying the triangle inequality and distributing the $\limsup$.

3. 
$$
Df(x) \leq Mf(x) + \abs{f(x)}
$$

Fix an $\alpha$ and fix an $\varepsilon$.
Choose a continuous $g$ such that $\norm{f-g}_1 < \varepsilon$.

Writing $f=f-g+g$, we have

\begin{align*}
Df(x) 
&\leq D(f-g)(x) + Dg(x) \\
&=D(f-g)(x) + 0 \\
&\leq M(f-g)(x) + \abs{(f-g)(x)}.
,\end{align*}

Then 
$$
Df(x) \geq \alpha \implies M(f-g)(x) \geq \frac{\alpha}{2}
$$ 
or 
$$
\abs{(f-g)(x)} \geq \frac{\alpha}{2}
.$$

So we have 
$$
\theset{x\suchthat Df(x) > \alpha} \subseteq \theset{x\suchthat M(f-g)(x) > \frac\alpha 2} \union \theset{x\suchthat \abs{f(x) - g(x)} > \frac\alpha 2}
.$$
Applying measures turns this into an inequality.

But then applying the maximal function theorem, we have

\begin{align*}
m(\theset{x\suchthat Df(x) > \alpha}) 
&\leq \frac{3^n}{\alpha/2} \norm{f-g}_1 + \frac 2 \alpha \norm{f-g}_1 \\
&\leq \varepsilon \left(\frac{2(3^n + 1)}{\alpha} \right)
.\end{align*}

$\qed$

> Note that somehow proving the maximal function theorem here really paved the way, and allows some generalization. Here we computed an average over a solid ball, but there is a notion of surface measure, so we can consider averaging over the surface of spheres, which can include more exotic objects like spheres in $\ZZ^d$.

*Proof of HL Maximal Function Theorem:*
Let 
$$
E_\alpha \definedas \theset{x\suchthat Mf(x) > \alpha}
.$$

If $x\in E_\alpha$, then it follows that there is a $B_x$ such that 
$$
\frac{1}{m(B_x)} \int_{B_x} \abs{f(y)} ~dy > \alpha \iff m(B_x) < \frac 1 \alpha \int_{B_x} \abs{f(y)} ~dy
.$$

Note that if $E_\alpha$ were compact, there would only be finitely many such balls, so let $K \subseteq E_\alpha$ be a compact subset.
We will be done if we can show that 
$$
m(K) < \frac{3^n}{\alpha} \norm{f}_1
,$$ 
since we can always find a compact $K$ such that $m(E_\alpha\setminus K)$ is small.

There exists a finite collection $\theset{B_k}^N$ such that each $B_k = B_x$ for some $x\in E_\alpha$, $K \subseteq \union B_k$, and 
$$
m(B_k) \leq \frac{1}{\alpha} \int_{B_k} \abs{f(y)}~dy
.$$

Supposing that the $B_k$ were disjoint (which they are not!), then we would be done since

\begin{align*}
m(K) 
&\leq \sum m(B_k) \\
&\leq \frac{1}{\alpha} \sum \int_{B_k} \abs{f(y)} ~dy \\
&\leq \frac{1}{\alpha} \int_{\RR^n} \abs{f(y)}
.\end{align*}

*Lemma (The Vitali Covering Lemma):*
Given any collection of balls $B_1, \cdots, B_N$, there exists a sub-collection $A_1, \cdots, A_M$ which are disjoint with 
$$
m(\union^N B_k) \leq 3^n \sum^M m(A_j)
.$$

> Note that this follows directly from picking the largest ball first, then picking further balls that avoid everything already picked and are chosen in decreasing order of size. The $3^n$ factor comes from the earlier fact that tripling the radius covers everything you didn't pick.

But now we can replace $B_k$ with such a sub-collection $A_k$ in the above set of inequalities, which proves the theorem.
$\qed$.


