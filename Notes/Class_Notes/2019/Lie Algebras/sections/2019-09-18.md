# Wednesday September 18

**Last time:**
The abstract Jordan Decomposition coincides with the actual Jordan Decomposition.
\begin{align*}
\phi: \lieg &\to \liegl(V) \\ 
x &\mapsto \phi(x) = \phi(x)_s + \phi(x)_n = \phi(x_n) + \phi(x_s) \\
x_s + x_n &\mapsto \phi(x_s) + \phi(x_n)
.\end{align*}

Therefore $x_s \actson V$ semisimply. 
The example we saw last time was $\lieg = \liesl(2, \CC)$, with a matrix $h = [1, 0; 0, -1]$ and $V = \bigoplus_{\lambda \in \CC} V_ \lambda$.

## Finite Dimensional Representations of $\liesl(2, \CC)$

### Weights and Maximal Vectors

**Definition:**
If $V_\lambda \neq 0$, then $V_\lambda$ is a *weight space* of $V$ and $\lambda \in \CC$ is a *weight* of $h$ in $V$. We then define $W_t(V) = \theset{\text{weights in } V}$.

**Lemma:**
If $v\in V_\lambda$ then $e\actson v \in V_{\lambda + 2}$ and $f\actson v \in V_{\lambda - 2}$.

*Proof:*
\begin{align*}
h \actson (e\actson v) = [h, e] \actson v + e\actson (h \actson v) \\
= 2e \actson v + \lambda e \actson v \\
= (\lambda +2 )e \actson v
.\end{align*}

and
\begin{align*}
h \actson (f\actson v) = [h, f] \actson v + f\actson (h \actson v) \\
= -2f \actson v + \lambda f \actson v \\
= (\lambda -2 )f \actson v
.\end{align*}

So if $V$ is a finite-dimensional $\lieg\dash$module, then there exists a $V_\lambda \neq 0$ such that $V_{\lambda + 2} = 0$. Any nonzero $v\in V_{\lambda}$ is called a *maximal vector*.

> Note: in category $\mathcal O$, these always exist?

*Some computations:*
Let $\lieg = \liegl(2, \CC)$

Then $V = \CC$ is the trivial module, and $g\actson V = 0$. 
So $W_t(V) = \theset{0}$, and $V = V_0$.

If $V = \CC^2$, then take the natural representation $\mathrm{span}_\CC\theset{v_1 = [1, 0], v_2 = [0, 1]}$.
Then $g\actson V$ by matrix multiplication, and if $h = [1, 0; 0, -1]$ then $h\actson v_1 = v_1$ and $h\actson v_2 = -v_2$ by just doing the matrix-vector multiplication.
Then $\CC([1, 0]) = V_1, \CC([0, 1]) = V_{-1}$, so $W_t(V) = \theset{\pm 1}$.

Taking $V = \CC^3 = \ad \lieg = \mathrm{span}_\CC \theset{e, f, h}$, then
\begin{align*}
h\actson f = [h, f] = -2f \\
h\actson h = [h, h] = 0h \\
h\actson e = [h, e] = 2e
.\end{align*}

So $W_t(V) = \theset{2, 0, -2}$ and $V_2 = \CC e, V_0 = \CC h, V_{-2} = \CC f$.

> Note the pattern: some largest value, then jumping by 2 to lower values, ending at negative the largest value. In some sense, the rest of the theory will reduce to the case of $\liesl(2, \CC)$.

**Lemma:**
Let $V$ be a finite dimensional simple $\liesl(2, \CC)\dash$module, and $V_0 \in V_\lambda$ a maximal vector.

Set $V_{-1} = 0, V_i = f^{(i)} \actson v_0$ (where $f^{(i)} = \frac{f^i}{i!}$). Then for all $i \geq 0$, we have

a. $h\actson v_i = (\lambda - 2i) v_i$
b. $f\actson v_i = (i+1)v_{i+1}$
c. $e\actson v_i = (\lambda - i + 1)v_{i-1}$

*Proof of (a):*
By lemma 7.1, we have $f\actson v_0 \in V_{\lambda - 2}$, and so inductively $f^{(i)}\actson v_0 \in V_{\lambda - 2i}$

*Proof of (b):*
By definition.

*Proof of (c):*
\begin{align*}
ie\actson v_i 
&= ie \actson \frac{f^i \actson v_0}{ i! }\\
&= e\actson (f\actson v_{i-1}) \\
&= [e,f] \actson v_{i-1} + f\actson (e\actson v_{i-1}) \\
&= h \actson v_{i-1} + f\actson((\lambda -i + 2)v_{i-2}) \text{ind} \\
&= (\lambda - 2i + 2) v_{i-2} + (\lambda + i - 2)(i-1 v_{i-1}) \\
&= i (\text{RHS})
.\end{align*}

**Theorem:**
If $V$ is a finite dimensional and simple, then $V \cong L(m)$ for some $m \in \ZZ_{\geq 0}$ where $L(m) = \mathrm{span}_\CC\theset{v_0, v_1, \cdots v_m}$ where each $v_i$ is of weight $m - 2i$.

Thus $L(m) = L(m)_m \oplus L(m)_{m-2} \oplus \cdots \oplus L(m)_{-m}$ where $\dim L(m)_\mu = 1$ for all $\mu$ and $\dim L(m) = m+1$.

*Proof:*
Pick a maximal vector $v_0 \in V_\lambda$ for any weight $\lambda$. 
Define $v_i$ as usual.
Let $m = \min \theset{i \suchthat V_i \neq 0,~ V_{i+1} = 0}$

![Image](figures/2019-09-18-09:42.png)\

**Definition:**
A module $V$ is a *highest weight module* of weight $\lambda$ if $V = \lieg\actson v_0$ for some maximal vector $v_0 \in V_\lambda$.

Then $\lambda$ is referred to as the *highest weight*, and $v_0$ is the *highest weight vector*.

**Corollary:**
If $V$ is finite-dimensional, then 

a. $V = \bigoplus_{\lambda \in \ZZ} V_\lambda$
b. The number of summands = $\dim V_0 + \dim V_1$.

*Proof of (a):*
By Weyl's theorem, we know $V = \oplus W_i$ for some simple $W_i$. By theorem 7.2, this is equal to $\oplus_{m\in \ZZ_{\geq 0}} L(m)^{\mu_m}$

*Proof of (b):*
$\dim V_0 = \#\theset{\text{summands where $m$ is even}}$ and 
$\dim V_1 = \#\theset{\text{summands where $m$ is odd}}$

$\qed$

*Remark:*
Let 
$$
V_d = \theset{f\in\CC[x,y] \suchthat \text{ $f$ is homogeneous of total degree $d$ }} = \mathrm{span}_\CC\theset{x^d, x^{d-1}y, \cdots, y^d}
.$$

Then $\liesl(2, \CC)\actson V_d$ by
\begin{align*}
e &\mapsto x \dd{}{y} \\
f &\mapsto y \dd{}{x} \\
h &\mapsto x\dd{}{x} - y\dd{}{y}
.\end{align*}

**Fact:**
For $L(m)$ and $\phi: \liesl(2, \CC) \to \liegl(L(m))$, define
$$
s = (\exp \phi(e)) \circ (\exp \phi(-f)) \circ (\exp \phi(e))
$$

Then $s(v_i) = -v_{m-i}$.
