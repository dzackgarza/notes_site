# Friday January 24th

A standard theorem about classifying simple modules in category $\OO$:

Theorem (Classification of Simple Modules)
: Every simple module in $\OO$ is isomorphic to $L(\lambda)$ for some $\lambda \in \lieh\dual$, and is determined uniquely up to isomorphism by its highest weight.
  Moreover, $\dim \hom_\OO(L(\mu), L(\lambda)) = \delta_{\lambda \mu}$.


Proof
:   Let $L \in \OO$ be irreducible.
    As observed in 1.2, $L$ has a maximal vector $v^+$ of some weight $\lambda$.

    Recall: can increase weights and reach a maximal in a finite number of steps.

    Since $L$ is irreducible, $L$ is generated by that weight vector, i.e. $L U(\lieg) \cdot v^+$, so $L$ must be a highest weight module.

    > Standard argument: use triangular decomposition.

    By the universal property, $L$ is a quotient of $M(\lambda)$.
    But this means $L \cong L(\lambda)$, the unique irreducible quotient of $M(\lambda)$.

    By Theorem 1.2 part g (see last Friday), $\dim \endo_\OO(L(\lambda)) = 1$ and $\hom_\OO(L(\mu), L(\lambda)) = 0$ since both entries are irreducible.

Theorem (1.2 f, Highest Weight Modules are Indecomposable)
: A highest weight module $M$ is indecomposable, i.e. can't be written as a direct sum of two nontrivial proper submodules.

Proof (of Theorem 1.2 f)
: Suppose $M = M_1 \oplus M_2$ where $M$ is a highest weight module of highest weight $\lambda$.
	Category $\OO$ is closed under submodules, so $M_i$ are weight modules and have weight-space decompositions.
	But $M_\lambda$ is 1-dimensional (triangular decomposition, only $\CC$ acts), and thus $M_\lambda \subset M_1$.
	Since $M_\lambda$ is a highest weight module, it generates the entire module, so $M \subset M_1$.
	The reverse holds as well, so $M = M_1$ and this forces $M_2 = 0$.

## 1.4: Maximal Vectors in Verma Modules

> 1.5: Examples in the case $\liesl(2)$, over $\CC$ as usual.

First, some review from Lie algebras.

Let $\lieg$ be any lie algebra, and take $u, v \in U(\lieg)$.
Recall that we have the formula $$uv = [uv] + vu,$$ where we use the definition $[uv] = uv - vu$.

Let $x, y_1, y_2$ be in $\lieg$, what is $[x, y_1 y_2]$?
Use the fact that $\ad x (y_1, y_2)$ acts as a derivation, and so $[x, y_1 y_2] = [x y_1]y_2 + y_1[x y_2]$, which is a bracket entirely in the Lie algebra.
This extends to an action on $U(\lieg)$ by the product rule.

Recall that $\liesl(2)$ is spanned by $y =[0,0; 1,0], h = [1,0; 0, -1], x = [0,1; 0,0]$, where each basis vector spans $\lien^-, \lieh, \lien$ respectively.
Then $[x y] = h, [h x] = 2x, [h y] = -2y$, so $E_{ij} E_{kl} = \delta_{jk} E_{il}$ (should be able to compute easily!).

Then $\lieh = \CC$, so $\lieh\dual \cong \CC$ where $\lambda \mapsto \lambda(h)$.
So we identify $\lambda$ with a complex number, this is kind of like a bundle of Verma modules over $\CC$.

Consider $M(1)$, then $\lambda = 1$ will denote $\lambda(h) = 1$.
As in any Verma module, $M(\lambda) \cong U(\lien^-) \tensor_\CC \CC_{\lambda}$.
We can think of $v^+$ as $1\tensor 1$, with the action $yv^+ = y1\tensor 1$.
Note that $y$ has weight $-2$.


Weight | Basis 
-----| ----- |
1   | $v^+$ |
-1  | $yv^+$ |
-3  | $y^2 v^+$ |
-5  | $y^3 v^+$ |

Consider how $x\actson y^2 v^+$.
Note that $x$ has weight $+2$.
We have 

\begin{align*}
x \cdot y^2 v^+ 
&= x \cdot y^2 \tensor 1_\lambda \\
&= ([x y^2] + y^2 x) \tensor 1 \\
&= ([xy]y + y[xy]) \tensor 1 + y^2 \tensor x\cdot 1 \quad\text{moving $x$ across the tensor because ?}\\
&= ([xy]y + y[xy]) \tensor 1 + 0  \quad\text{since $x$ is maximal} \\
&= (hy + yh) \tensor 1 \\
&= hy \tensor 1 + y\tensor h\cdot 1 \\
&= hy \tensor 1 + \lambda(h)1 \\
&= hy \tensor 1 + 1 \\
&= ([xy] + yh)\tensor 1 + y\tensor 1 \\
&= -2y \tensor 1 + y\tensor 1 + y\tensor 1 \\
&= 0
.\end{align*}


So $y$ moves us downward through the table, and $x$ moves upward, except when going from $-3\to -1$ in which case the result is zero.

Thus there exists a morphism $\phi: M(-3) \to M(1)$, with image $U(\lieg) y^2 v^+ = U(\lien^-) y^2 v^+$.
So the image of $\phi$ is everything spanned by the bases in the rows $-3, -5, \cdots$, which is exactly $M(-3)$.
So $M(-3) \injects M(1)$ as a submodule.

> Motivation for next section: we want to find Verma modules which are themselves submodules of Verma modules.

It turns out that $\im \phi \cong N(1)$.
We should have $M(1) / N(1) \cong L(1)$.
What is the simple module of weight 1 for $\liesl(2)$?
The weights of $L(n)$ are $n, n-2, n-4, \cdots, -n$, so the representations are parameterized by $n\in \ZZ^{+}$.
These are the Verma modules for $\liesl(2)$.
What happens is that $y\actson -n \to -n-2$ gives a maximal vector, so the calculation above roughly goes through the same way.
So we'll have a similar picture with $L(n)$ at the top.

## Back to 1.4

*Question 1:* 
What are the submodules of $M(\lambda)$?

*Question 2:*
What are the Verma submodules $M(\mu) \subset M(\lambda)$?
Equivalently, when do maximal vectors of weight $\mu < \lambda$ (the interesting case) lie in $M(\lambda)$?

*Question 3:*
As a special case, when do maximal vectors of weight $\lambda - k\alpha$ for $\alpha \in \Delta$ lie in $M(\lambda)$ for $k\in \ZZ^+$?

Fix a Chevalley basis for $\lieg$ (see section 0.1) $h_1, \cdots, h_\ell \in \lieh$ and $x_\alpha \in \lieg_\alpha$ and $y_\alpha \in \lieg_{-\alpha}$ for $\alpha \in \Phi^+$.
Let $\Delta = \theset{\alpha_1, \cdots, \alpha_\ell}$ and let $x_i = x_{\alpha_i}, y_i = y_{\alpha_i}$ be chosen such that $[x_i y_i] = h_i$.


Lemma
: For $k\geq 0$ and $1\leq i, j \leq \ell$, then

	a. $[x_j, y_i^{k+1}] = 0$ if $j\neq i$

	b. $[h_j, y_i^{k+1}] = -(k+1) \alpha_i(h_j) y_i^{k+1}$.

	c. $[x_i, y_i^{k+1}] = -(k+1) y_i(k\cdot 1 - h_i)$.


Proof (sketch)
: Both easy to prove by induction since $[x_j, y_i] \to \alpha_j - \alpha_i \not\in \Phi$ is a difference of simple roots.

	For $k=0$, all identities are easy.
	For $k> 0$, an inductive formula that uses the derivation property, which we'll do next class.
