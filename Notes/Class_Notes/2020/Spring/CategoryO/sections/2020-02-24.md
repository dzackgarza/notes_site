# Monday February 24th

## Antidominant Weights

Recall that for $\lambda \in \lieh\dual$, we can associate $\Phi_{[\lambda]}$ and $W_{[\lambda]}$ and consider $W_{[\lambda]} \cdot \lambda$.
When $\lambda \in \Lambda$ is integral and $\mu \in W\lambda \intersect \Lambda^+$, we have $M(\mu) \to L(\mu)$ its simple quotient, which is finite-dimensional.

Definition (Antidominant)
:   $\lambda \in \lieh\dual$ is *antidominant* if $(\lambda + \rho, \alpha\dual) \not\in \ZZ^{> 0}$ for all $\alpha \in \Phi^+$.
    Dually, $\lambda$ is *dominant* if $(\lambda + \rho, \alpha\dual)\not\in\ZZ^{<0}$ for all $\alpha\in\Phi^+$.

Note that most weights are both dominant and antidominant.
Example: take $\lambda = -\rho$.
We won't use the dominant condition often.

Remark
:   For $\lambda \in \lieh\dual$, $W\cdot \lambda$ and $W_{[\lambda]}\cdot \lambda$ contain at least one antidominant weight.
    Let $\mu$ be minimal in either set with respect to the usual ordering on $\lieh\dual$.
    If $(\mu + \rho, \alpha\dual) \in \ZZ^{>0}$ for some $\alpha > 0$, then $s_\alpha \cdot \mu < \mu$, which is a contradiction.
    So any minimal weight will be antidominant.

Proposition (Equivalent Definitions of Antidominant)
:   Fix $\lambda\in\lieh\dual$, as well as $W_{[\lambda]}, \Phi_{[\lambda]}$,
    Then define $\Phi^+_{[\lambda]} \definedas \Phi_{[\lambda]} \intersect \Phi^+ \supset \Delta_{[\lambda]}$.
    TFAE:

    a. $\lambda$ is antidominant.
    b. $(\lambda + \rho, \alpha\dual) \leq 0$ for all $\alpha\in \Delta_{[\lambda]}$.
    c. $\lambda \leq s_\alpha \cdot \lambda$ for all $\alpha \in \Delta_{[\lambda]}$.
    d. $\lambda \leq w\cdot \lambda$ for all $w\in W_{[\lambda]}$.

    In particular, there is a unique antidominant weight in $W_{[\lambda]} \cdot \lambda$.

Proof (a implies b)
:   $(\lambda + \rho, \alpha\dual) \in \ZZ$ for all $\alpha \in \Delta_{[\lambda]}$ or $\Phi^+{[\lambda]}$.

Proof (b implies a)
:   Suppose (b) and $(\lambda + \rho, \alpha\dual) \in \ZZ$ for all $\alpha\in\Phi^+$.
    Then $\alpha \in \Phi^+ \intersect \Phi_{[\lambda]}$, which is equal to $\Phi^+_{[\lambda]}$ by the homework problem.
    So $\alpha \in \ZZ^+ \Delta_{[\lambda]}$, and thus (claim) $(\lambda + \rho, \alpha\dual) \leq 0$ by (b).
    Why? Replace $\alpha\dual$ with a bunch of other $\alpha_i\dual$ for which $(\lambda + \rho, \alpha_i\dual) < 0$ and sum.

Proof (b iff c)
:   $s_\alpha \cdot \lambda = \lambda - (\lambda + \rho, \alpha\dual)\alpha$.

Proof (d implies c)
:   Trivial due to definitions.

Proof (c implies d)
:   Use induction on $\ell(w)$ in $W_{[\lambda]}$.
    Assume (c), and hence (b), and consider $\ell(w) = 0 \implies w = 1$.
    For the inductive step, if $\ell(w) > 0$, write $w = w' s_\alpha$ in $W_{[\lambda]}$ with $\alpha \in \Delta_{[\lambda]}$.
    Then $\ell(w') = \ell(w) - 1$, and by Proposition 0.3.4, $w(\alpha) < 0$.
    
    We can then write 
    $$
    \lambda - w\cdot \lambda = (\lambda - w'\cdot \lambda) + (w' \cdot \lambda - w\cdot \lambda)
    .$$
  
    The first term is $\leq 0$ by hypothesis, so noting that the $w$ action is not linear but still an action, we have
    
    \begin{align*}
    w' \cdot \lambda - w\cdot \lambda 
    &= w\cdot s_\alpha \cdot \lambda - w\cdot \lambda \\
    &= w(s_\alpha \lambda - \lambda) \quad\text{by 1.8b} \\
    &= w(-(\lambda+\rho, \alpha\dual)\alpha) \\
    &= -(\lambda + \rho, \alpha\dual)(w\alpha) \\
    &= -1 (\in \ZZ^-)(<0)
    ,\end{align*}

    which is a product of three negatives and thus negative.

A remark from page 56:
Even when $\lambda \not \in \Lambda$, we can decompose $\OO_\chi$ into subcategories $\OO_\lambda$.
We then recover $\OO_\chi$ as the sum over $\OO_\lambda$ for antidominant $\lambda$'s in the intersection of the linkage class with cosets of $\Lambda_r$.
These are the homological blocks.

## Tensoring Verma and Finite Dimensional Modules

> First step toward understanding translation functors, which help with calculations.

By Corollary 1.2, we know that every $N\in \OO$ has a filtration with every section being a highest weight module.
We will improve this result to show that if $M$ is finite-dimensional and $V$ is a Verma module, then $V\tensor M$ has a filtration whose sections are all Verma modules.
This is important for studying projectives in a couple of sections.

Theorem (Sections of Finite-Dimensional Tensor Verma are Verma)
:   Let $M$ be a finite dimensional $U(\lieg)\dash$module.
    Then $T \definedas M(\lambda) \tensor M$ has a finite filtration with sections $M(\lambda + \mu)$ for $\mu \in \Pi(M)$, occuring with the same multiplicities.

Proof
:   Use the tensor identity
    
    \begin{align*}
    \qty{ U(\lieg) \tensor_{U(\lieb)} L} \tensor_\CC M 
    \cong U(\lieg)\tensor_{U(\lieb)} \qty{ L \tensor_\CC M  }
    ,\end{align*}

    where 

    - $L \in U(\lieb)\dash$mod.
    - $M \in U(\lieg)\dash$mod.
    - $L\tensor M \in U(\lieb)\dash$mod via the tensor action.

    The LHS is a $U(\lieg)\dash$module via the tensor action, and the $RHS$ has an induced $U(\lieg)\dash$action.

    > See proof in Knapp's "Lie Groups, Lie Algebras, and Cohomology".
    > This is true more generally if $\lieg$ is any lie algebra and $\lieb\leq \lieg$ any lie-subalgebra.
    
    Recall from page 18 that the functor $\ind_\lieh^\lieg$ is exact on finite-dimensional $\lieb\dash$modules.
    Assume $L, M$ are finite-dimensional, and set $N \definedas L \tensor_\CC M$.
    Take a basis $v_1, \cdots, v_n$ of weight vectors for $N$ of weights $\nu_1, \cdots, \nu_n$.
    Order these such that $\nu_i \leq \nu_j \iff i<j$. \newline

    Set $N_k$ to be the $U(\lieb)\generators{v_k, \cdots, v_n}$ for $1\leq k \leq n$, which is a decreasing filtration since acting by $U(\lieb)$ moves along this list of vectors/weights to the right.
    By induction on $n$, this filtration induces a filtration on $U(\lieg)\tensor_{U(\lieb)} N$ whose sections are Verma modules.
    
    This yields
    $$
    \ind_\lieb^\lieg N_k / \ind_\lieb^\lieg N_{k+1} \cong M(\nu_k)
    .$$
    
    The intermediate quotients will be 1-dimensional submodules, which will induce up to highest weight modules. 
    We'll finish the proof next time.

