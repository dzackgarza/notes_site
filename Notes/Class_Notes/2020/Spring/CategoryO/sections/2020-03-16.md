# Monday March 16th

Proposition (Chains of Containments of Vermas for Dominant Integral)
:   Suppose $\lambda + \rho$ is dominant integral, then

    - $M(w\cdot \lambda) \subset M(\lambda)$ for all $w\in W$
    - $[M(\lambda): L(w\cdot \lambda)] > 0$ for all $w\in W$

    More precisely, if $w = s_1 \cdots s_\ell$ is reduced with $s_i = s_{\alpha_i}$ with $\alpha_i \in \Delta$ and $\lambda_k = s_k \cdots s_1 \cdot \lambda$, then
    $$
    M(w\cdot \lambda) = M(\lambda_n) \subset M(\lambda_{n-1}) \subset \cdots \subset M(\lambda_0) = M(\lambda)
    $$

    Moreover $(\lambda_k + \rho, \alpha_{k+1}\dual) \in \ZZ^+$ for $0\leq k \leq n-1$ and so
    $$
    \lambda_n \leq \lambda_{n-1} \leq \cdots \leq \lambda_0
    .$$

Proof
: By induction on $n = \ell(w)$.
  The $n=0$ case is obvious.
  For $\ell(w) = k+1$, write $w'= s_k \cdots s_1$.
  From section 0.3, $(w')\inv \alpha_{k+1} > 0$.
  We can compute
  \begin{align*}
  (\lambda_k + \rho, \alpha_{k+1}\dual)
  &= (w' \cdots \lambda + \rho, \alpha_{k+1}\dual) \\
  &= (w'(\lambda + \rho), \alpha_{k+1}\dual) \\
  &= (\lambda + \rho, (w')\inv \alpha_{k+1}\dual) \\
  &= (\lambda + \rho, ((w')\inv \alpha_{k+1})\dual) \\
  &\in \ZZ^{+}
  \end{align*}
  since $\lambda + \rho \in \Lambda^+$ and $(w')\inv \alpha_{k+1} \in \Phi^+$.


  This means that $\lambda_{k+1} = s_{k+1} \lambda_k \leq \lambda_k$.
  By proposition 1.4, reformulated in terms of the dot action, we have a map $M(\lambda_{k+1}) \injects M(\lambda_k)$, and nonzero morphisms are injective by 4.2a.



Exercise (4.3)
: If $\lambda + \rho \in \Lambda^+$, $\soc M(\lambda) = M(w_o \cdot \lambda)$, and moreover if $\lambda \in \Lambda_0^+$ then the inclusions in the proposition are all proper.


Remark
: For general $\mu \in \Lambda$, it is not so easy to decide when $M(w\cdot \mu) \subset M(\mu)$.
  The basic problem is that Proposition 1.4 only works for *simple* roots, whereas we can have $s_\gamma \cdot \mu < \mu$ for $\gamma \in \Phi^+\setminus \Delta$ with no obvious way to constrct an embedding
  $M(s_\gamma \cdot \mu) \subset M(\mu)$.
  See the following example.

Example
: Let $\lieg = \liesl(3, \CC)$.

    \begin{center}
    \begin{tikzpicture}
    \pgfplotsset{every x tick label/.append style={font=\tiny, yshift=0.5ex}}
    \pgfplotsset{every y tick label/.append style={font=\tiny, xshift=0.5ex}}
    \begin{axis}[
        xmin=-10,
        xmax=10,
        ymin=-2,
        ymax=2,
        xtick = {0},
        ytick = {0},
        axis equal,
        axis lines=middle,
        disabledatascaling]

    \node[font=\tiny] at (axis cs:-4,5) [anchor=north west] {$\beta$};
    \node[font=\tiny] at (axis cs:5,0) [anchor=north west] {$\alpha$};
    \node[font=\tiny] at (axis cs:5,5) [anchor=north west] {$\alpha + \beta$};
    \node[font=\tiny] at (axis cs:6,8) [anchor=north west] {$\liesl(3, \CC)$};

    \begin{scope}[thick, draw=blue]
      \draw[-][opacity=0.9, postaction={decorate}] (axis cs:-5.0, -5.0) -- (axis cs:5,5);
      \draw[-][opacity=0.9, postaction={decorate}] (axis cs:-5.0, 5.0) -- (axis cs:5,-5);
      \draw[-][opacity=0.9, postaction={decorate}] (axis cs:-5.0, 0.0) -- (axis cs:5,0);
    \end{scope}

    \end{axis}
    \end{tikzpicture}
    \end{center}

    We don't know if there's a diagonal map indicated by the question mark in the following diagram:

    \begin{center}
    \begin{tikzcd}
    &  & \lambda \in \Lambda^+                                                                                                 &  &                                    \\
    &  &                                                                                                                       &  &                                    \\
    \mu = s_\alpha \cdot \lambda \arrow[rruu] &  &                                                                                                                       &  & s_\beta \cdot \lambda \arrow[lluu] \\
    &  &                                                                                                                       &  &                                    \\
    &  & s_\alpha s_\beta \cdot \lambda = s_{\alpha + \beta} \lambda = s_\gamma \lambda \arrow[lluu, "?", dashed] \arrow[rruu] &  &
    \end{tikzcd}
    \end{center}


Next few sections: any root reflection that moves downward through the ordering induces a containment of Verma modules.

## (4.4) Simplicity Criterion: The Integral Case

Theorem (Vermas Equal Quotients iff Antidominant Weight)
: Let $\lambda \in \lieh\dual$ be any weight.
  Then $M(\lambda) = L(\lambda) \iff \lambda$ is antidominant.

The proof for $\lambda$ integral is fairly easy, because antidominance reduces to a condition involving simple roots, where we can use our Verma module embedding criterion from Proposition 1.4.

Proof (Integral Case)
:   Assume $\lambda \in \Lambda$.

    $\implies$:
    Assume $M(\lambda)$ is simple but $\lambda$ is not antidominant.
    Then since $\lambda \in \Lambda$, $(\lambda + \rho, \alpha\dual)$ is a positive integer for some $\alpha \in \Delta$.
    But then $s_\alpha \lambda < \lambda$ so $M(s_\alpha \cdot \lambda) \subset M(\lambda)$ by 1.4 and 4.2.
    But then $N(\lambda) \neq 0$, which contradicts irreducibility.

    $\impliedby$:
    Assume $\lambda$ is antidominant.
    By proposition 3.5, $\lambda < w\cdot \lambda$ for all $w\in W$.
    Since all composition factors of $M(\lambda)$ and $L(w\cdot \lambda)$ where $w\cdot \lambda \leq \lambda$.
    This can only happen if $w\cdot \lambda = \lambda$, and so the only possible composition factor is $L(\lambda)$.
    Since $[M(\lambda) : L(\lambda)]$ is always equal to one, $M(\lambda)$ is simple.

Remark
: The reverse implication still works in general if $W$ is replaced by $W_{[\lambda]}$.
To extend the forward implication, we need to understand embeddings $M(s_\beta \cdots \lambda) \injects M(\lambda)$ when $\beta$ is not simple.

## Existence of Embeddings (Preliminaries)


Lemma (Commuting Nilpotents)
: Let $\mfa$ be a nilpotent Lie algebra (e.g. $\lien^-$) and $x\in \mfa, u\in U(\mfa)$, then for every $n\in \ZZ^+$ there exists a $t\in \ZZ^+$ such that $x^t u \in U(\mfa) x^n$.

> See Engel's theorem


Proof
:   Use the fact that $\ad x$ acts nilpotently on $U(\mfa)$, so there exists a $q\geq 0$ such that $\qty{\ad x}^{q+1}u = 0$.

    Let $\ell_x, r_x$ be left and right multiplication by $x$ on $U(\mfa)$.
    Then $\ad x = \ell_x - r_x$, and $\ell_x, r_x \ad x$ all commute.

    Choosing $t \geq q + n$, we have

    \begin{align*}
    x^t u &= \ell_x^t u \\
    &= (r_x + \ad x)^t u \\
    &= \sum_{i=0}^t {t \choose i} r_x^{t-i} \qty{\ad x}^i u \\
    &= \sum_{i=0}^q {t \choose i} \qty{\qty{\ad x}^iu  }x^{t-i} \\
    &\in U(\mfa) x^{t-q} \\
    &\subset U(\mfa) x^n
    \end{align*}

> This will be useful when moving things around by positive roots that are not simple.
